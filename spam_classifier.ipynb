{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Spam Classifier using SVM and Gaussian Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data from the link\n",
    "'https://drive.google.com/open?id=0ByJLBTmJojjzdTdvRC10TnhCa2M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                         Rofl. Its true to its name\n",
       "1  The guy did some bitching but I acted like i'd...\n",
       "2  Pity, * was in mood for that. So...any other s...\n",
       "3               Will ü b going to esplanade fr home?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = pd.read_csv('./spam_filtering/ham', sep='|', names = ['text'], dtype=str)\n",
    "spam = pd.read_csv('./spam_filtering/spam', sep='|', names = ['text'], dtype=str)\n",
    "ham.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You have 1 new message. Please call 08712400200.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent! Please call 09061743811 from landline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear 0776xxxxxxx U've been invited to XCHAT. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U 447801259231 have a secret admirer who is lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0   You have 1 new message. Please call 08712400200.\n",
       "1  Urgent! Please call 09061743811 from landline....\n",
       "2  Dear 0776xxxxxxx U've been invited to XCHAT. T...\n",
       "3  U 447801259231 have a secret admirer who is lo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the text data\n",
    "# Removing stop words and special characters\n",
    "def make_dictionary(data_1, data_2):\n",
    "    emails_1 = list(data_1.text)  # list of emails  \n",
    "    emails_2 = list(data_2.text)\n",
    "    all_words = []       \n",
    "    \n",
    "    for mail in emails_1:    \n",
    "                    words = mail.split()\n",
    "                    all_words += words\n",
    "    for mail in emails_2:    \n",
    "                    words = mail.split()\n",
    "                    all_words += words\n",
    "    \n",
    "    dictionary = Counter(all_words)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = make_dictionary(spam, ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete words which are not alphabetical and whose length is 1.\n",
    "list_to_remove = list(dictionary.keys())\n",
    "for item in list_to_remove:\n",
    "    if item.isalpha() == False: \n",
    "        del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "        del dictionary[item]\n",
    "dictionary = dictionary.most_common(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words\n",
    "\n",
    "Transform texts into bag of words matrix(number of columns == number of unique words, number of rows == number of documents(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each mail into 3000 feature vector, where each feature is a key from above dictionary.\n",
    "def extract_features(mail): \n",
    "    mails = list(mail.text)\n",
    "    features_matrix = np.zeros((len(mails),3000))\n",
    "    mail_no = 0\n",
    "    for mail in mails:\n",
    "        words = mail.split()\n",
    "        for word in words:\n",
    "            wordID = 0\n",
    "            for i,d in enumerate(dictionary):\n",
    "                if d[0] == word:\n",
    "                    wordID = i\n",
    "                    break\n",
    "            features_matrix[mail_no,wordID] = words.count(word)\n",
    "        mail_no = mail_no + 1     \n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_input = extract_features(spam)\n",
    "ham_input = extract_features(ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((747, 3000), (4803, 3000))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_input.shape, ham_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_train = spam_input[:700]\n",
    "ham_train = ham_input[:4000]\n",
    "spam_test = spam_input[700:]\n",
    "ham_test = ham_input[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 3000), (4000, 3000), (47, 3000), (803, 3000))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train.shape, ham_train.shape, spam_test.shape, ham_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.vstack((spam_train,ham_train))\n",
    "train_y = [1 for i in range(700)] + [0 for i in range(4000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.vstack((spam_test,ham_test))\n",
    "test_y = [1 for i in range(47)] + [0 for i in range(803)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4700, 3000), 4700, (850, 3000), 850)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, len(train_y), test_X.shape, len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MultinomialNB()\n",
    "model2 = LinearSVC()\n",
    "\n",
    "model1.fit(train_X,train_y)\n",
    "model2.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = model1.predict(test_X)\n",
    "result_2 = model2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for MultinomialNB\n",
      "Accuracy: 0.981176\n",
      "Precision: 0.803922\n",
      "Recall: 0.872340\n",
      "F1 score: 0.836735\n",
      "Cohens kappa: 0.826765\n",
      "ROC AUC: 0.929944\n",
      "[[793  10]\n",
      " [  6  41]]\n"
     ]
    }
   ],
   "source": [
    "print('Metric for MultinomialNB')\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_y, result_1)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y, result_1)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y, result_1)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y, result_1)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(test_y, result_1)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(test_y, result_1)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_y, result_1)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for Linear SVM\n",
      "Accuracy: 0.983529\n",
      "Precision: 0.923077\n",
      "Recall: 0.765957\n",
      "F1 score: 0.836735\n",
      "Cohens kappa: 0.828614\n",
      "ROC AUC: 0.881111\n",
      "[[800   3]\n",
      " [ 11  36]]\n"
     ]
    }
   ],
   "source": [
    "print('Metric for Linear SVM')\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_y, result_2)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y, result_2)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y, result_2)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y, result_1)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(test_y, result_2)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(test_y, result_2)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_y, result_2)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
